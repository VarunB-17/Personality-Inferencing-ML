{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "data_train = pd.read_json(\"processed_training.json\")\n",
    "data_val = pd.read_json(\"processed_validation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "# Taggeddocument for training data\n",
    "taggedDocuments_train = []\n",
    "for index, data_point_post in data_train.iterrows():\n",
    "    taggedDocument_train =  TaggedDocument(words=data_train.at[index, 'posts'], tags=[data_train.at[index, 'type']])\n",
    "    taggedDocuments_train.append(taggedDocument_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taggeddocument for validation data\n",
    "taggedDocuments_val = []\n",
    "for index, data_point_post in data_val.iterrows():\n",
    "    taggedDocument_val =  TaggedDocument(words=data_val.at[index, 'posts'], tags=[data_val.at[index, 'type']])\n",
    "    taggedDocuments_val.append(taggedDocument_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Dov2Vec model\n",
    "model = Doc2Vec(vector_size=80, min_count=2, epochs=15)\n",
    "model.build_vocab(taggedDocuments_train)\n",
    "\n",
    "model.train(taggedDocuments_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vector_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(model, taggedDocuments):\n",
    "    \"\"\"\n",
    "    infering vectors from the model \n",
    "    \"\"\"\n",
    "    sents = taggedDocuments[0:45865]\n",
    "    tags, posts = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return tags, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the posts and types\n",
    "type_train, posts_train = data_splitter(model, taggedDocuments_train)\n",
    "type_val, posts_val = data_splitter(model, taggedDocuments_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying logistic regression\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=-1, solver='sag')\n",
    "logreg.fit(posts_train, type_train)\n",
    "\n",
    "import winsound\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c6b3b74e3638>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Validating the (logreg) model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "# Validating the (logreg) model\n",
    "type_pred = logreg.predict(posts_val)\n",
    "print(classification_report(type_val, type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.85      0.81      0.83      2298\n",
      "           I       0.82      0.86      0.84      2273\n",
      "\n",
      "    accuracy                           0.83      4571\n",
      "   macro avg       0.83      0.83      0.83      4571\n",
      "weighted avg       0.83      0.83      0.83      4571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=50)\n",
    "neigh.fit(posts_train, type_train)\n",
    "type_pred = neigh.predict(posts_val)\n",
    "print(classification_report(type_val, type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test set NB ONLY USE AFTER BEST HYPERPARAMETER HAS BEEN CHOSEN\n",
    "data_test = pd.read_json(\"processed_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrains Dov2Vec model\n",
    "taggedDocuments_train.extend(taggedDocuments_val)\n",
    "model = Doc2Vec(vector_size=80, min_count=2, epochs=15)\n",
    "model.build_vocab(taggedDocuments_train)\n",
    "model.train(taggedDocuments_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taggeddocument for test data\n",
    "taggedDocuments_test = []\n",
    "for index, data_point_post in data_test.iterrows():\n",
    "    taggedDocument_test =  TaggedDocument(words=data_test.at[index, 'posts'], tags=[data_test.at[index, 'type']])\n",
    "    taggedDocuments_test.append(taggedDocument_test)\n",
    "    \n",
    "type_test, posts_test = data_splitter(model, taggedDocuments_test)\n",
    "type_train, posts_train = data_splitter(model, taggedDocuments_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.87      0.85      0.86      2514\n",
      "           I       0.86      0.88      0.87      2564\n",
      "\n",
      "    accuracy                           0.87      5078\n",
      "   macro avg       0.87      0.87      0.87      5078\n",
      "weighted avg       0.87      0.87      0.87      5078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying logistic regression\n",
    "logreg = LogisticRegression(n_jobs=-1, solver='sag')\n",
    "logreg.fit((posts_train), (type_train))\n",
    "\n",
    "# Testing the (logreg) model\n",
    "type_pred = logreg.predict(posts_test)\n",
    "print(classification_report(type_test, type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505513981882631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.50      0.50      0.50      2488\n",
      "           I       0.52      0.51      0.51      2590\n",
      "\n",
      "    accuracy                           0.51      5078\n",
      "   macro avg       0.51      0.51      0.51      5078\n",
      "weighted avg       0.51      0.51      0.51      5078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier as a baseline to prove our model's effectiveness\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=0)\n",
    "dummy.fit(posts_train+posts_val, type_train+type_val)\n",
    "\n",
    "type_pred = dummy.predict(posts_test)\n",
    "print(classification_report(type_test, type_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5895c19eaeaaf2f51c408f07c95071cd65f0794f3cdacfedf343cff40747f1b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
