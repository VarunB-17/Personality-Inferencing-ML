{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "data_train = pd.read_json(\"processed_training.json\")\n",
    "data_val = pd.read_json(\"processed_validation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "# Taggeddocument for training data\n",
    "taggedDocuments_train = []\n",
    "for index, data_point_post in data_train.iterrows():\n",
    "    taggedDocument_train =  TaggedDocument(words=data_train.at[index, 'posts'], tags=[data_train.at[index, 'type']])\n",
    "    taggedDocuments_train.append(taggedDocument_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taggeddocument for validation data\n",
    "taggedDocuments_val = []\n",
    "for index, data_point_post in data_val.iterrows():\n",
    "    taggedDocument_val =  TaggedDocument(words=data_val.at[index, 'posts'], tags=[data_val.at[index, 'type']])\n",
    "    taggedDocuments_val.append(taggedDocument_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# creating the Dov2Vec model\n",
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(taggedDocuments_train)\n",
    "\n",
    "model.train(taggedDocuments_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vector_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(model, taggedDocuments):\n",
    "    \"\"\"\n",
    "    infering vectors from the model \n",
    "    \"\"\"\n",
    "    sents = taggedDocuments[0:45865]\n",
    "    tags, posts = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return tags, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the posts and types\n",
    "type_train, posts_train = data_splitter(model, taggedDocuments_train)\n",
    "type_val, posts_val = data_splitter(model, taggedDocuments_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1, solver='sag')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying logistic regression\n",
    "# TODO Should we include hyperparam C?\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=-1, solver='sag')\n",
    "logreg.fit(posts_train, type_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.86      0.86      0.86      3438\n",
      "           I       0.86      0.86      0.86      3418\n",
      "\n",
      "    accuracy                           0.86      6856\n",
      "   macro avg       0.86      0.86      0.86      6856\n",
      "weighted avg       0.86      0.86      0.86      6856\n",
      "\n",
      "Testing F1 score: 0.8573514194308273\n"
     ]
    }
   ],
   "source": [
    "# Validating the (logreg) model\n",
    "logreg.score()\n",
    "type_pred = logreg.predict(posts_val)\n",
    "print(classification_report(type_val, type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test set NB ONLY USE AFTER BEST HYPERPARAMETER HAS BEEN CHOSEN\n",
    "data_test = pd.read_json(\"processed_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrains Dov2Vec model\n",
    "taggedDocuments_train.extend(taggedDocuments_val)\n",
    "model.train(taggedDocuments_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taggeddocument for test data\n",
    "taggedDocuments_test = []\n",
    "for index, data_point_post in data_test.iterrows():\n",
    "    taggedDocument_test =  TaggedDocument(words=data_test.at[index, 'posts'], tags=[data_test.at[index, 'type']])\n",
    "    taggedDocuments_test.append(taggedDocument_test)\n",
    "    \n",
    "type_test, posts_test = data_splitter(model, taggedDocuments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying logistic regression\n",
    "logreg.fit((posts_train+posts_val), (type_train+type_val))\n",
    "\n",
    "# Testing the (logreg) model\n",
    "type_pred = logreg.predict(posts_test)\n",
    "print(classification_report(type_test, type_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505513981882631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.50      0.50      0.50      2488\n",
      "           I       0.52      0.51      0.51      2590\n",
      "\n",
      "    accuracy                           0.51      5078\n",
      "   macro avg       0.51      0.51      0.51      5078\n",
      "weighted avg       0.51      0.51      0.51      5078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier as a baseline to prove our model's effectiveness\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=0)\n",
    "dummy.fit(posts_train+posts_val, type_train+type_val)\n",
    "\n",
    "type_pred = dummy.predict(posts_test)\n",
    "print(classification_report(type_test, type_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5895c19eaeaaf2f51c408f07c95071cd65f0794f3cdacfedf343cff40747f1b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
